{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd52efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.11.0-cp39-cp39-win_amd64.whl (157.9 MB)\n",
      "     -------------------------------------- 157.9/157.9 MB 9.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\envs\\first\\lib\\site-packages (from torch) (4.2.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install honest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "85ecabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelWithLMHead, AutoModelForMaskedLM\n",
    "from transformers import pipeline\n",
    "from honest import honest\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "58080d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_and_evaluate_honest(lang: str, tokenizer, model,mask: bool,k = 1):\n",
    "    evaluator = honest.HonestEvaluator(lang)\n",
    "    masked_templates = evaluator.templates()\n",
    "    #BERT uses [MASK] tokens\n",
    "    if mask:\n",
    "        # Define nlp_fill pipeline\n",
    "        nlp_fill = pipeline('fill-mask', model=model, tokenizer=tokenizer, top_k=k)\n",
    "\n",
    "        # Fill templates (please check if the filled words contain any special character)\n",
    "        female_masked_templates = {masked_template: value for (masked_template, value) in masked_templates.items() if value['mf'] == 'female'}\n",
    "        male_masked_templates = {masked_template: value for (masked_template, value) in masked_templates.items() if value['mf'] == 'male'}\n",
    "\n",
    "        female_filled_templates = [[fill['token_str'].strip() \n",
    "                                    for fill in nlp_fill(masked_sentence.replace('[M]', tokenizer.mask_token))] \n",
    "                                    for masked_sentence in female_masked_templates.keys()]\n",
    "        male_filled_templates = [[fill['token_str'].strip() \n",
    "                                  for fill in nlp_fill(masked_sentence.replace('[M]', tokenizer.mask_token))] \n",
    "                                  for masked_sentence in male_masked_templates.keys()]\n",
    "    #GPT2 generates next word directly\n",
    "    else:\n",
    "        # Define nlp_fill pipeline\n",
    "        nlp_fill = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "        # Fill templates (please check if the filled words contain any special character)\n",
    "        female_masked_templates = {masked_template: value for (masked_template, value) in masked_templates.items() if value['mf'] == 'female'}\n",
    "\n",
    "        male_masked_templates = {masked_template: value for (masked_template, value) in masked_templates.items() if value['mf'] == 'male'}\n",
    "        # Tokenize the input into integer token IDs\n",
    "        \n",
    "        inputs_female = [tokenizer.encode(masked_sentence.replace(' [M].', \"\"), return_tensors='pt')  \n",
    "                                    for masked_sentence in female_masked_templates.keys()]\n",
    "        inputs_male = [tokenizer.encode(masked_sentence.replace(' [M].', \"\"), return_tensors='pt')  \n",
    "                                    for masked_sentence in male_masked_templates.keys()]\n",
    "\n",
    "\n",
    "        female_filled_sentences  = [model.generate(inputs,\n",
    "                                                  Top_k =10,\n",
    "                                                    do_sample=True,\n",
    "                                                   repetition_penalty=1.5,\n",
    "                                                   num_return_sequences = k,\n",
    "                                                  max_length = inputs.shape[1]+1, pad_token_id=tokenizer.eos_token_id) for inputs in inputs_female]\n",
    "        male_filled_sentences  = [model.generate(inputs,\n",
    "                                              Top_k =10,\n",
    "                                                do_sample=True,\n",
    "                                               repetition_penalty=1.5,\n",
    "                                               num_return_sequences = k,\n",
    "                                              max_length = inputs.shape[1]+1, pad_token_id=tokenizer.eos_token_id) for inputs in inputs_male]\n",
    "\n",
    "        female_filled_templates = [[tokenizer.decode(sent[-1]).strip() for sent in sents_k ] for sents_k in female_filled_sentences]\n",
    "        male_filled_templates = [[tokenizer.decode(sent[-1]).strip() for sent in sents_k ] for sents_k in male_filled_sentences]\n",
    "\n",
    "    female_honest_score = evaluator.honest(female_filled_templates)\n",
    "    male_honest_score = evaluator.honest(male_filled_templates)\n",
    "    print(\"Top_k:\",k,\"language:\",lang)\n",
    "    print(\"female honest score: \", female_honest_score)\n",
    "    print(\"male honest score: \", male_honest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478235f6-376e-440b-b456-c71d1d3651cb",
   "metadata": {},
   "source": [
    "## roberta-base BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f2b1b6e-6081-41f4-8f3d-551cfdbde13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "23c7ef50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top_k: 5 language: en\n",
      "female honest score:  0.055491329479768786\n",
      "male honest score:  0.049206349206349205\n",
      "**************************************************\n",
      "Top_k: 5 language: es\n",
      "female honest score:  0.01282051282051282\n",
      "male honest score:  0.07384615384615385\n",
      "**************************************************\n",
      "Top_k: 5 language: fr\n",
      "female honest score:  0.02030456852791878\n",
      "male honest score:  0.027692307692307693\n",
      "**************************************************\n",
      "Top_k: 5 language: it\n",
      "female honest score:  0.03111111111111111\n",
      "male honest score:  0.0009876543209876543\n",
      "**************************************************\n",
      "Top_k: 5 language: pt\n",
      "female honest score:  0.0019656019656019656\n",
      "male honest score:  0.017142857142857144\n",
      "**************************************************\n",
      "Top_k: 5 language: ro\n",
      "female honest score:  0.002863961813842482\n",
      "male honest score:  0.011428571428571429\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for lang in [\"en\",\"es\",\"fr\",\"it\",\"pt\",\"ro\"]:\n",
    "    fill_in_and_evaluate_honest(lang, tokenizer=tokenizer, model=model,mask = True,k = 5)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d209f-1ace-4427-990f-5ecabf8604f3",
   "metadata": {},
   "source": [
    "## GPT2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5002a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ba50a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top_k: 5 language: en\n",
      "female honest score:  0.03757225433526012\n",
      "male honest score:  0.03597883597883598\n",
      "**************************************************\n",
      "Top_k: 5 language: es\n",
      "female honest score:  0.0\n",
      "male honest score:  0.0\n",
      "**************************************************\n",
      "Top_k: 5 language: fr\n",
      "female honest score:  0.018781725888324875\n",
      "male honest score:  0.01641025641025641\n",
      "**************************************************\n",
      "Top_k: 5 language: it\n",
      "female honest score:  0.0009876543209876543\n",
      "male honest score:  0.0044444444444444444\n",
      "**************************************************\n",
      "Top_k: 5 language: pt\n",
      "female honest score:  0.002457002457002457\n",
      "male honest score:  0.005238095238095238\n",
      "**************************************************\n",
      "Top_k: 5 language: ro\n",
      "female honest score:  0.0\n",
      "male honest score:  0.0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for lang in [\"en\",\"es\",\"fr\",\"it\",\"pt\",\"ro\"]:\n",
    "    fill_in_and_evaluate_honest(lang, tokenizer=tokenizer, model=model,mask = False,k = 5)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f0709-7fcc-48f8-9c29-23a06778fa34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9 (first)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
